"""
AWS Bedrock Claude í´ë¼ì´ì–¸íŠ¸ - í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë²„ì „
ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ê³  ì§€ì¹¨ ì¤€ìˆ˜ë¥¼ ê°•í™”í•œ ë²„ì „
"""
import boto3
import json
import logging
from typing import Dict, Any, Iterator, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

# Bedrock Runtime í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')

# Claude 4.0 ëª¨ë¸ ì„¤ì •
CLAUDE_MODEL_ID = "us.anthropic.claude-sonnet-4-20250514-v1:0"
MAX_TOKENS = 16384
TEMPERATURE = 0.3  # ì¼ê´€ì„± ìˆëŠ” ì¶œë ¥ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ìœ ì§€

class PromptComponent:
    """í”„ë¡¬í”„íŠ¸ ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ì„ ëª…í™•íˆ ì •ì˜"""
    
    PERSONA = "AGENT_PERSONA"           # AIì˜ í˜ë¥´ì†Œë‚˜/ì „ë¬¸ì„± ì •ì˜
    GUIDELINES = "CORE_GUIDELINES"      # í•µì‹¬ ê°€ì´ë“œë¼ì¸ (ìœ ì—°í•˜ê²Œ ì ìš©)
    KNOWLEDGE = "DOMAIN_KNOWLEDGE"      # ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ (ì ê·¹ í™œìš©)

def create_enhanced_system_prompt(
    prompt_data: Dict[str, Any], 
    engine_type: str,
    use_enhanced: bool = True,
    flexibility_level: str = "balanced"  # "strict", "balanced", "flexible"
) -> str:
    """
    ìœ ì—°í•˜ê³  ì§€ëŠ¥ì ì¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ì§€ì¹¨ê³¼ ì§€ì‹ì„ ê· í˜•ìˆê²Œ í™œìš©
    - ìœ ì—°ì„± ë ˆë²¨ ì¡°ì ˆ ê°€ëŠ¥
    """
    prompt = prompt_data.get('prompt', {})
    files = prompt_data.get('files', [])
    
    # 1. PERSONA - AIì˜ ì „ë¬¸ì„±ê³¼ í˜ë¥´ì†Œë‚˜
    persona = prompt.get('description', f'{engine_type} ì „ë¬¸ ì—ì´ì „íŠ¸')
    
    # 2. GUIDELINES - í•µì‹¬ ê°€ì´ë“œë¼ì¸
    guidelines = prompt.get('instruction', 'ì œê³µëœ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.')
    
    # 3. KNOWLEDGE - ë„ë©”ì¸ ì§€ì‹
    knowledge_base = _process_knowledge_base(files, engine_type)
    
    # ìœ ì—°ì„± ë ˆë²¨ì— ë”°ë¥¸ ì§€ì¹¨ ê°•ë„ ì¡°ì ˆ
    flexibility_phrases = {
        "strict": "ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ì‘ì—…í•˜ì„¸ìš”:",
        "balanced": "ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì°¸ê³ í•˜ë˜, ìƒí™©ì— ë§ê²Œ ìœ ì—°í•˜ê²Œ ì ìš©í•˜ì„¸ìš”:",
        "flexible": "ë‹¤ìŒì€ ì°¸ê³  ê°€ì´ë“œë¼ì¸ì…ë‹ˆë‹¤. ì°½ì˜ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìš°ì„ ì‹œí•˜ì„¸ìš”:"
    }
    
    if use_enhanced:
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° - ì—­í•  ë¶„ë¦¬ ëª…í™•í™”
        system_prompt = f"""## ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜
{persona}

## í•µì‹¬ ê°€ì´ë“œë¼ì¸
{flexibility_phrases.get(flexibility_level, flexibility_phrases["balanced"])}
{guidelines}

{knowledge_base if knowledge_base else ""}

## ì‘ì—… ì ‘ê·¼ ë°©ì‹
â€¢ ê°€ì´ë“œë¼ì¸ì€ ë°©í–¥ì„±ì„ ì œì‹œí•˜ëŠ” ì°¸ê³ ì‚¬í•­ì…ë‹ˆë‹¤
â€¢ ì œê³µëœ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì „ë¬¸ì„± ìˆëŠ” ë‹µë³€ ìƒì„±
â€¢ ì‚¬ìš©ìì˜ ì˜ë„ì™€ ë§¥ë½ì„ ìš°ì„  ê³ ë ¤
â€¢ ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ì‘ë‹µì´ ê°€ì¥ ì¤‘ìš”
â€¢ í•„ìš”ì‹œ ê°€ì´ë“œë¼ì¸ì„ ìœ ì—°í•˜ê²Œ í•´ì„í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ ë„ì¶œ

ğŸ’¡ í•µì‹¬: ì§€ì‹ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ì„±ì„ ë°œíœ˜í•˜ë˜, ê³¼ë„í•˜ê²Œ ê²½ì§ë˜ì§€ ì•Šì€ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”."""
    else:
        # ìµœì†Œ êµ¬ì¡° í”„ë¡¬í”„íŠ¸
        system_prompt = f"""ë‹¹ì‹ ì€ {persona}

ëª©í‘œ: {guidelines}
{_format_knowledge_base_basic(files)}"""
    
    logger.info(f"System prompt created for {engine_type} with {flexibility_level} flexibility: {len(system_prompt)} chars")
    return system_prompt

def _process_knowledge_base(files: List[Dict], engine_type: str) -> str:
    """ì§€ì‹ë² ì´ìŠ¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ êµ¬ì„±"""
    if not files:
        return ""
    
    contexts = []
    contexts.append("\n## ğŸ“š ë„ë©”ì¸ ì§€ì‹ë² ì´ìŠ¤")
    contexts.append("ë‹¤ìŒ ì§€ì‹ì„ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”:\n")
    
    for idx, file in enumerate(files, 1):
        file_name = file.get('fileName', f'ë¬¸ì„œ_{idx}')
        file_content = file.get('fileContent', '')
        
        if file_content.strip():
            contexts.append(f"""
### [{idx}] {file_name}
```
{file_content.strip()}
```""")
    
    contexts.append("\nğŸ’¡ **í™œìš© ê°€ì´ë“œ**: ìœ„ ì§€ì‹ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì „ë¬¸ì ì´ê³  ì •í™•í•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.")
    
    return '\n'.join(contexts)

def _format_knowledge_base_basic(files: List[Dict]) -> str:
    """ê¸°ë³¸ ì§€ì‹ë² ì´ìŠ¤ í¬ë§·íŒ…"""
    if not files:
        return ""
    
    contexts = ["\n=== ì§€ì‹ë² ì´ìŠ¤ ==="]
    for file in files:
        file_name = file.get('fileName', 'unknown')
        file_content = file.get('fileContent', '')
        if file_content.strip():
            contexts.append(f"\n[{file_name}]")
            contexts.append(file_content.strip())
    
    return '\n'.join(contexts)

def _process_file_contexts(files: List[Dict]) -> str:
    """íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì²˜ë¦¬"""
    if not files:
        return ""
    
    contexts = []
    contexts.append("\n### ì œê³µëœ ì°¸ì¡° ìë£Œ:")
    
    for idx, file in enumerate(files, 1):
        file_name = file.get('fileName', f'ë¬¸ì„œ_{idx}')
        file_content = file.get('fileContent', '')
        file_type = file.get('fileType', 'text')
        
        if file_content.strip():
            contexts.append(f"""
#### [{idx}] {file_name}
- ìœ í˜•: {file_type}
- ë‚´ìš©:
```
```""")
    
    contexts.append("\n**ì°¸ì¡° ìë£Œ í™œìš© ì§€ì¹¨**: ìœ„ ìë£Œë¥¼ í•„ìš”ì— ë”°ë¼ ì°¸ì¡°í•˜ë˜, ì£¼ì–´ì§„ ì§€ì¹¨ì„ ìš°ì„ ì‹œí•˜ì„¸ìš”.")
    
    return '\n'.join(contexts)

def _format_file_contexts_basic(files: List[Dict]) -> str:
    """ê¸°ë³¸ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
    if not files:
        return ""
    
    contexts = ["\n=== ì°¸ì¡° ìë£Œ ==="]
    for file in files:
        file_name = file.get('fileName', 'unknown')
        file_content = file.get('fileContent', '')
        if file_content.strip():
            contexts.append(f"\n[{file_name}]")
            contexts.append(file_content.strip())
    
    return '\n'.join(contexts)

def create_user_message_with_anchoring(
    user_message: str,
    response_format: Optional[str] = None,
    examples: Optional[List[str]] = None
) -> str:
    """
    Response Anchoringì„ í™œìš©í•œ ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
    ì‘ë‹µì˜ ì‹œì‘ ë¶€ë¶„ì´ë‚˜ êµ¬ì¡°ë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì˜ ì‘ë‹µì„ ìœ ë„
    """
    enhanced_message = user_message
    
    # ì˜ˆì‹œ ì¶”ê°€ (Few-shot learning)
    if examples:
        enhanced_message = f"""ë‹¤ìŒì€ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:
{chr(10).join(f'ì˜ˆì‹œ {i+1}: {ex}' for i, ex in enumerate(examples))}

ì´ì œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:
{user_message}"""
    
    # ì‘ë‹µ í˜•ì‹ ì•µì»¤ë§
    if response_format:
        enhanced_message += f"\n\nì‘ë‹µ í˜•ì‹:\n{response_format}"
    
    return enhanced_message

def validate_instruction_compliance(
    response: str,
    original_instruction: str,
    validation_keywords: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    ê°„ë‹¨í•œ ì‘ë‹µ ê²€ì¦ (ì„ íƒì  ì‚¬ìš©)
    """
    # ë³µì¡í•œ ê²€ì¦ ëŒ€ì‹  í”„ë¡¬í”„íŠ¸ í’ˆì§ˆì— ì§‘ì¤‘
    validation_result = {
        "response_length": len(response),
        "has_content": bool(response.strip())
    }
    
    # ì„ íƒì  í‚¤ì›Œë“œ ì²´í¬ (í•„ìš”ì‹œë§Œ)
    if validation_keywords:
        found_keywords = [kw for kw in validation_keywords if kw.lower() in response.lower()]
        validation_result["found_keywords"] = found_keywords
    
    return validation_result

def stream_claude_response_enhanced(
    user_message: str,
    system_prompt: str,
    use_cot: bool = True,
    max_retries: int = 1
) -> Iterator[str]:
    """
    í–¥ìƒëœ Claude ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
    
    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        use_cot: Chain-of-Thought ì‚¬ìš© ì—¬ë¶€
        max_retries: ì¬ì‹œë„ íšŸìˆ˜
    """
    # Chain-of-Thought í”„ë¡¬í”„íŒ… ì ìš©
    if use_cot and "ë¶„ì„" in user_message or "ì„¤ëª…" in user_message:
        user_message = f"ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ë©° ë‹µë³€í•´ì£¼ì„¸ìš”:\n{user_message}"
    
    messages = [{"role": "user", "content": user_message}]
    
    for attempt in range(max_retries + 1):
        try:
            body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": MAX_TOKENS,
                "temperature": TEMPERATURE,
                "system": system_prompt,
                "messages": messages,
                "top_p": 0.7,  # ë‹¤ì–‘ì„± ì œì–´
                "top_k": 40    # ì„ íƒ ê°€ëŠ¥í•œ í† í° ì œí•œ
            }
            
            logger.info(f"Calling Bedrock (attempt {attempt + 1}/{max_retries + 1})")
            logger.info(f"Request body: {json.dumps(body)[:500]}...")  # body ë‚´ìš© ë¡œê¹…
            
            response = bedrock_runtime.invoke_model_with_response_stream(
                modelId=CLAUDE_MODEL_ID,
                body=json.dumps(body)
            )
            
            stream = response.get('body')
            if stream:
                for event in stream:
                    chunk = event.get('chunk')
                    if chunk:
                        chunk_obj = json.loads(chunk.get('bytes').decode())
                        
                        if chunk_obj.get('type') == 'content_block_delta':
                            delta = chunk_obj.get('delta', {})
                            if delta.get('type') == 'text_delta':
                                text = delta.get('text', '')
                                if text:
                                    yield text
                        
                        elif chunk_obj.get('type') == 'message_stop':
                            logger.info("Claude streaming completed successfully")
                            return
            
        except Exception as e:
            logger.error(f"Error in attempt {attempt + 1}: {str(e)}")
            if attempt == max_retries:
                yield f"\n\nAI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨ (ì‹œë„: {max_retries + 1}): {str(e)}"
            else:
                logger.info(f"Retrying in 1 second...")
                import time
                time.sleep(1)

def get_prompt_effectiveness_metrics(
    prompt_data: Dict[str, Any],
    response: str
) -> Dict[str, Any]:
    """
    í”„ë¡¬í”„íŠ¸ íš¨ê³¼ì„± ë©”íŠ¸ë¦­ ì¸¡ì •
    """
    metrics = {
        "prompt_length": len(str(prompt_data)),
        "response_length": len(response),
        "has_description": bool(prompt_data.get('prompt', {}).get('description')),
        "has_instructions": bool(prompt_data.get('prompt', {}).get('instruction')),
        "file_count": len(prompt_data.get('files', [])),
        "estimated_tokens": len(response.split()) * 1.3,  # ëŒ€ëµì ì¸ í† í° ì¶”ì •
        "timestamp": datetime.now().isoformat()
    }
    
    return metrics

# ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„± ìœ ì§€
def create_system_prompt(prompt_data: Dict[str, Any], engine_type: str) -> str:
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    # ëª¨ë“  ì—”ì§„ì— balanced ì ìš© (H8ë„ í¬í•¨)
    return create_enhanced_system_prompt(prompt_data, engine_type, use_enhanced=True, flexibility_level="balanced")

def stream_claude_response(user_message: str, system_prompt: str) -> Iterator[str]:
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    return stream_claude_response_enhanced(user_message, system_prompt)